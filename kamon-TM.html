<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <title>家紋分類サイト（Teachable Machine + OpenCV.js）</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body { font-family: "Segoe UI", "Hiragino Kaku Gothic ProN", sans-serif; background:#fff; color:#000; text-align:center; margin:2rem;}
    h1 { font-size:2rem; margin-bottom:0.5rem;}
    #status { margin:1rem 0; color:#000;}
    input[type=file]{margin:1rem;}
    canvas{margin-top:1rem; max-width:60%; border:1px solid #444;}
    .result{margin-top:1rem; font-size:1.2rem;}
  </style>
</head>

<body>
  <h1>🏯 家紋分類サイト</h1>
  <p>画像をアップロードすると、AIが <b>丸・四角・三角・なし</b> のいずれかを判定します。</p>

  <p id="status">⏳ モデル読み込み中...</p>
  <input type="file" id="file" accept="image/*">
  <canvas id="canvas"></canvas>
  <div class="result" id="result"></div>

 <!-- TensorFlow.js -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>

<!-- Teachable Machine -->
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>

<!-- OpenCV.js（安定CDN＋確認付き） -->
<script async 
  src="https://docs.opencv.org/4.x/opencv.js"
  onload="document.getElementById('status').textContent += ' ✅ OpenCV.js読み込み成功';"
  onerror="alert('⚠️ OpenCV.jsの読み込みに失敗しました。もう一度再読み込みしてください。');">
</script>


  <script>
    const MODEL_URL = "https://teachablemachine.withgoogle.com/models/JssL1cK-Y/";  // ← あなたのモデルURLに置き換え
    let tmModel;

    const statusEl = document.getElementById('status');
    const fileInput = document.getElementById('file');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const resultEl = document.getElementById('result');

    // ---- モデルを読み込む ----
    async function loadModel() {
      try {
        const modelURL = MODEL_URL + "model.json";
        const metadataURL = MODEL_URL + "metadata.json";
        tmModel = await tmImage.load(modelURL, metadataURL);
        statusEl.textContent = "✅ モデル読み込み完了！画像を選んでください。";
      } catch (err) {
        console.error(err);
        statusEl.textContent = "❌ モデル読み込み失敗：URLやネットワークを確認してください。";
      }
    }

    loadModel();

    // ---- ファイル選択時 ----
    fileInput.addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (!file || !tmModel) return;

      const img = new Image();
      img.onload = async () => {
        // Canvasに描画
        canvas.width = img.width;
        canvas.height = img.height;
        ctx.drawImage(img, 0, 0);

        // TMモデルで推論
        const prediction = await tmModel.predict(img);
        prediction.sort((a, b) => b.probability - a.probability);
        const top = prediction[0];

        resultEl.innerHTML = `🔍 結果：<b>${top.className}</b>（確率 ${(top.probability*100).toFixed(1)}%）`;

        // OpenCVで囲みを描画（もし形があれば）
        // OpenCVで囲みを描画（外枠は除外）
if (typeof cv !== 'undefined') {
  const src = cv.imread(canvas);
  const gray = new cv.Mat();
  cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

  // 線が黒・背景が白の画像が多いなら “線を白” にする方が輪郭が取りやすい
  // 必要に応じて THRESH_BINARY に戻してください
  cv.threshold(gray, gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU);

  // ノイズ除去（細かい点を消す）
  const kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(3, 3));
  cv.morphologyEx(gray, gray, cv.MORPH_OPEN, kernel);
  kernel.delete();

  const contours = new cv.MatVector();
  const hierarchy = new cv.Mat();
  cv.findContours(gray, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

  const W = src.cols, H = src.rows;
  const MIN_AREA  = 400;      // 小さすぎるゴミを除外
  const MAX_FRAC  = 0.90;     // 画像面積の90%を超える巨大輪郭は除外
  const EDGE_MGN  = 2;        // 端から2px以内に触れていたら外枠とみなす

  let vis = src.clone();

  for (let i = 0; i < contours.size(); ++i) {
    const cnt = contours.get(i);
    const area = cv.contourArea(cnt);
    if (area < MIN_AREA) { cnt.delete(); continue; }

    const r = cv.boundingRect(cnt);

    const touchesEdge =
      r.x <= EDGE_MGN ||
      r.y <= EDGE_MGN ||
      (r.x + r.width)  >= (W - EDGE_MGN) ||
      (r.y + r.height) >= (H - EDGE_MGN);

    const isHuge = area > MAX_FRAC * W * H;

    // ★ 外枠・端接触・巨大輪郭はスキップ
    if (touchesEdge || isHuge) { cnt.delete(); continue; }

    // ここから可視化（必要に応じて色を変えてOK）
    cv.rectangle(
      vis,
      new cv.Point(r.x, r.y),
      new cv.Point(r.x + r.width, r.y + r.height),
      new cv.Scalar(0, 255, 0, 255),
      2
    );

    cnt.delete();
  }

  cv.imshow(canvas, vis);
  vis.delete();
  src.delete(); gray.delete(); contours.delete(); hierarchy.delete();
}

      };
      img.src = URL.createObjectURL(file);
    });
  </script>
</body>
</html>






